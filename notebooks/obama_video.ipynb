{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.backends import cudnn\n",
    "import skimage.io\n",
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = Experiment(api_key=\"E3oWJUSFulpXpCUQfc5oGz0zY\", project_name=\"obama_video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "channels = 3\n",
    "seq_length = 20\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, seq_length, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.seq_length = seq_length\n",
    "        self.transform = transform\n",
    "        self.filenames = sorted(glob.glob(os.path.join(root_dir, \"*.png\")))\n",
    "    def __len__(self):\n",
    "        return len(self.filenames) - (seq_length - 1)\n",
    "    def __getitem__(self, idx):\n",
    "        images = [skimage.io.imread(self.filenames[idx+i]) for i in range(seq_length)]\n",
    "        if self.transform:\n",
    "            images = list(map(self.transform, images))\n",
    "        else:\n",
    "            images = list(map(transforms.ToTensor(), images))\n",
    "        return torch.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataset(\"/home/santiago/Downloads/obama/images/\", 20, transform=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.CenterCrop(1080),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "workers = 4\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoAutoencoder(nn.Module):\n",
    "    def __init__(self, img_size, latent_dim):\n",
    "        self.img_size = img_size\n",
    "        self.ds_size = self.img_size // 2**5\n",
    "        self.latent_dim = latent_dim\n",
    "        super(VideoAutoencoder, self).__init__()\n",
    "        \n",
    "        self.enc_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 1, 1),\n",
    "            nn.Conv2d(16, 16, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.BatchNorm2d(16, 0.8),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            nn.Conv2d(32, 32, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.Conv2d(64, 64, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.Conv2d(128, 128, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.Conv2d(256, 256, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "            nn.BatchNorm2d(256, 0.8)\n",
    "        )\n",
    "        self.enc_proj = nn.Sequential(\n",
    "            nn.Linear(256*self.ds_size**2, latent_dim),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.1),\n",
    "#             nn.BatchNorm2d(latent_dim, 0.8)\n",
    "        )\n",
    "        self.enc_lstm = nn.LSTM(latent_dim, latent_dim, 1, dropout=0.1)\n",
    "        \n",
    "        self.dec_lstm = nn.LSTMCell(latent_dim, latent_dim)\n",
    "        self.dec_proj = nn.Sequential(\n",
    "#             nn.BatchNorm2d(128, 0.8),\n",
    "            nn.Linear(latent_dim, 256*self.ds_size**2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dec_conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(256, 0.8),\n",
    "            nn.ConvTranspose2d(256, 256, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.ConvTranspose2d(128, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(16, 0.8),\n",
    "            nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(16, 3, 3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = x.permute(1, 0, 2, 3, 4)\n",
    "        enc_reps = []\n",
    "        for step in x.split(1):\n",
    "            step = step[0]\n",
    "            conv = self.enc_conv(step)\n",
    "            conv = conv.view(conv.shape[0], 256*self.ds_size**2)\n",
    "            proj = self.enc_proj(conv)\n",
    "            enc_reps.append(proj)\n",
    "        out, states = self.enc_lstm(torch.stack(enc_reps))\n",
    "        return states[0][0]  # hidden state\n",
    "    \n",
    "    def decode(self, h, steps):\n",
    "        init = torch.zeros_like(h)\n",
    "        c = torch.zeros_like(h)\n",
    "        decoded = []\n",
    "        for i in range(steps):\n",
    "            h, c = self.dec_lstm(init, (h, c))\n",
    "            proj = self.dec_proj(step)\n",
    "            proj = proj.view(proj.shape[0], 256, self.ds_size, self.ds_size)\n",
    "            dec = self.dec_conv(proj)\n",
    "            decoded.append(dec)\n",
    "        return torch.stack(reversed(decoded)).permute(1, 0, 2, 3, 4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.encode(x)\n",
    "        y = self.decode(h, x.shape[1])\n",
    "        loss = F.l1_loss(x, y) ** 1.1\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VideoAutoencoder(img_size, latent_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs = Variable(data.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.forward(inputs)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
