{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.backends import cudnn\n",
    "import skimage.io\n",
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = Experiment(api_key=\"E3oWJUSFulpXpCUQfc5oGz0zY\", project_name=\"obama_avb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "channels = 3\n",
    "seq_len = 20\n",
    "img_latent_dim = 64\n",
    "seq_latent_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, root_dir, seq_len, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.seq_len = seq_len\n",
    "        self.transform = transform\n",
    "        self.filenames = sorted(glob.glob(os.path.join(root_dir, \"*.png\")))\n",
    "    def __len__(self):\n",
    "        return len(self.filenames) - (self.seq_len - 1)\n",
    "    def __getitem__(self, idx):\n",
    "        images = [skimage.io.imread(self.filenames[idx+i]) for i in range(self.seq_len)]\n",
    "        if self.transform:\n",
    "            images = list(map(self.transform, images))\n",
    "        else:\n",
    "            images = list(map(transforms.ToTensor(), images))\n",
    "        return torch.stack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VideoDataset(\"/home/santiago/Downloads/obama/images/\", 20, transform=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.CenterCrop(1024),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "workers = 4\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAVB(nn.Module):\n",
    "    def __init__(self, img_size, channels, latent_dim):\n",
    "        super(ImageAVB, self).__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.channels = channels\n",
    "        self.latent_dim = latent_dim\n",
    "        self.ds_size = img_size // 2**5\n",
    "        \n",
    "        self.gen_proj = nn.Linear(self.latent_dim, 256*self.ds_size**2)\n",
    "        self.gen_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ConvTranspose2d(256, 256, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.ConvTranspose2d(128, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.ConvTranspose2d(64, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.BatchNorm2d(16, 0.8),\n",
    "            nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ConvTranspose2d(16, self.channels, 3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.enc_proj = nn.Linear(self.latent_dim, img_size**2)\n",
    "        self.enc_blocks = nn.Sequential(\n",
    "            nn.Conv2d(self.channels+1, 16, 3, 1, 1),\n",
    "            nn.Conv2d(16, 16, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(16, 0.8),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            nn.Conv2d(32, 32, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.Conv2d(64, 64, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.Conv2d(128, 128, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.Conv2d(256, 256, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(256, 0.8)\n",
    "        )\n",
    "        self.enc_layer = nn.Linear(256*self.ds_size**2, self.latent_dim)\n",
    "        \n",
    "        self.dis_proj = nn.Linear(self.latent_dim, self.img_size**2)\n",
    "        self.dis_blocks = nn.Sequential(\n",
    "            nn.Conv2d(self.channels+1, 16, 3, 1, 1),\n",
    "            nn.Conv2d(16, 16, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(16, 0.8),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            nn.Conv2d(32, 32, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.Conv2d(64, 64, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.Conv2d(128, 128, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.Conv2d(256, 256, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(256, 0.8)\n",
    "        )\n",
    "        self.dis_layer = nn.Sequential(\n",
    "            nn.Linear(256*self.ds_size**2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def sample_prior(self, s):\n",
    "        if self.training:\n",
    "            m = torch.zeros((s.data.shape[0], self.latent_dim))\n",
    "            std = torch.ones((s.data.shape[0], self.latent_dim))\n",
    "            d = Variable(torch.normal(m,std))\n",
    "        else:\n",
    "            d = Variable(torch.zeros((s.data.shape[0], self.latent_dim)))\n",
    "        return d.cuda()\n",
    "    \n",
    "    def discriminator(self, x, z):\n",
    "        z_proj = self.dis_proj(z)\n",
    "        z_proj = z_proj.view(z_proj.shape[0], 1, self.img_size, self.img_size)\n",
    "        i = torch.cat((x, z_proj), dim=1)\n",
    "        h = self.dis_blocks(i)\n",
    "        h = h.view(h.shape[0], 256*self.ds_size**2)\n",
    "        out = self.dis_layer(h)\n",
    "        return out\n",
    "    \n",
    "    def sample_posterior(self, x):\n",
    "        prior_proj = self.enc_proj(self.sample_prior(x))\n",
    "        prior_proj = prior_proj.view(prior_proj.shape[0], 1, self.img_size, self.img_size)\n",
    "        i = torch.cat((x, prior_proj), dim=1)\n",
    "        h = self.enc_blocks(i)\n",
    "        h = h.view(h.shape[0], 256*self.ds_size**2)\n",
    "        out = self.enc_layer(h)\n",
    "        return out\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        z_proj = self.gen_proj(z)\n",
    "        z_proj = z_proj.view(z_proj.shape[0], 256, self.ds_size, self.ds_size)\n",
    "        out = self.gen_blocks(z_proj)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z_p = self.sample_prior(x)\n",
    "        z_q = self.sample_posterior(x)\n",
    "        \n",
    "        log_d_prior = self.discriminator(x, z_p)\n",
    "        log_d_posterior = self.discriminator(x, z_q)\n",
    "        \n",
    "        dis_loss = torch.mean(\n",
    "            torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                log_d_posterior, torch.ones_like(log_d_posterior))\n",
    "            + torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                log_d_prior, torch.zeros_like(log_d_prior)))\n",
    "        \n",
    "        x_recon = self.decoder(z_q)\n",
    "        recon_likelihood = -torch.nn.functional.binary_cross_entropy(\n",
    "                                                x_recon, x)*x.data.shape[0]\n",
    "        \n",
    "        gen_loss = torch.mean(log_d_posterior)-torch.mean(recon_likelihood)\n",
    "        \n",
    "        return z_p, z_q, dis_loss, gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceAVB(nn.Module):\n",
    "    def __init__(self, vector_dim, seq_len, latent_dim):\n",
    "        super(SequenceAVB, self).__init__()\n",
    "        \n",
    "        self.vector_dim = vector_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.gen_lstm = nn.LSTM(self.vector_dim, self.latent_dim, num_layers=2, dropout=0.25)\n",
    "        \n",
    "        self.enc_lstm = nn.LSTM(self.vector_dim, self.latent_dim, num_layers=2, dropout=0.25)\n",
    "        \n",
    "        self.dis_lstm = nn.LSTM(self.vector_dim, self.latent_dim, num_layers=2, dropout=0.25)\n",
    "        self.dis_layer = nn.Sequential(\n",
    "            nn.Linear(4*self.latent_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def sample_prior(self, s):\n",
    "        if self.training:\n",
    "            m = torch.zeros((2, s.data.shape[1], self.latent_dim))\n",
    "            std = torch.ones((2, s.data.shape[1], self.latent_dim))\n",
    "            d = (Variable(torch.normal(m,std)).cuda(), Variable(torch.normal(m,std)).cuda())\n",
    "        else:\n",
    "            d = (Variable(torch.zeros((2, s.data.shape[1], self.latent_dim))).cuda(), Variable(torch.zeros((2, s.data.shape[1], self.latent_dim))).cuda())\n",
    "        return d\n",
    "    \n",
    "    def discriminator(self, x, z):\n",
    "        _, states = self.dis_lstm(x, z)\n",
    "        h = torch.cat((states[0].view(states[0].shape[1], 2*self.latent_dim), states[1].view(states[1].shape[1], 2*self.latent_dim)), dim=1)\n",
    "        out = self.dis_layer(h)\n",
    "        return out\n",
    "    \n",
    "    def sample_posterior(self, x):\n",
    "        _, states = self.enc_lstm(x, self.sample_prior(x))\n",
    "        return (torch.stack([states[0][1], states[0][0]]), torch.stack([states[1][1], states[1][0]]))\n",
    "    \n",
    "    def decoder(self, z, num_steps):\n",
    "        step = Variable(torch.zeros(1, z[0].shape[1], self.latent_dim)).cuda()\n",
    "        decoded = []\n",
    "        for i in range(num_steps):\n",
    "            step, z = self.gen_lstm(step, z)\n",
    "            decoded.append(step[0])\n",
    "        return torch.stack(list(reversed(decoded)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z_p = self.sample_prior(x)\n",
    "        z_q = self.sample_posterior(x)\n",
    "        \n",
    "        log_d_prior = self.discriminator(x, z_p)\n",
    "        log_d_posterior = self.discriminator(x, z_q)\n",
    "        \n",
    "        dis_loss = torch.mean(\n",
    "            torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                log_d_posterior, torch.ones_like(log_d_posterior))\n",
    "            + torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                log_d_prior, torch.zeros_like(log_d_prior)))\n",
    "        \n",
    "        x_recon = self.decoder(z_q, self.seq_len)\n",
    "        recon_likelihood = -torch.nn.functional.binary_cross_entropy(\n",
    "                                                self.sigmoid(x_recon), self.sigmoid(x))*x.data.shape[1]\n",
    "        \n",
    "        gen_loss = torch.mean(log_d_posterior)-torch.mean(recon_likelihood)\n",
    "        \n",
    "        return z_p, z_q, dis_loss, gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoAVB(nn.Module):\n",
    "    def __init__(self, img_size, channels, img_latent_dim, seq_len, seq_latent_dim):\n",
    "        super(VideoAVB, self).__init__()\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.channels = channels\n",
    "        self.img_latent_dim = img_latent_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.seq_latent_dim = seq_latent_dim\n",
    "        self.ds_size = img_size // 2**5\n",
    "        \n",
    "        self.img_model = ImageAVB(self.img_size, self.channels, self.img_latent_dim)\n",
    "        self.seq_model = SequenceAVB(self.img_latent_dim, self.seq_len, self.seq_latent_dim)\n",
    "        \n",
    "        self.dis_proj = nn.Linear(self.img_latent_dim, self.img_size**2)\n",
    "        self.dis_blocks = nn.Sequential(\n",
    "            nn.Conv2d(self.channels+1, 16, 3, 1, 1),\n",
    "            nn.Conv2d(16, 16, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(16, 0.8),\n",
    "            \n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            nn.Conv2d(32, 32, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(32, 0.8),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            nn.Conv2d(64, 64, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, 1, 1),\n",
    "            nn.Conv2d(128, 128, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, 1, 1),\n",
    "            nn.Conv2d(256, 256, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.BatchNorm2d(256, 0.8)\n",
    "        )\n",
    "        self.dis_rep = nn.Linear(256*self.ds_size**2, self.img_latent_dim)\n",
    "        self.dis_lstm = nn.LSTM(self.img_latent_dim, self.seq_latent_dim, num_layers=2, dropout=0.25)\n",
    "        self.dis_layer = nn.Sequential(\n",
    "            nn.Linear(4*self.seq_latent_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def sample_prior(self, s):\n",
    "        frame_p = []\n",
    "        for frame in s.split(1):\n",
    "            frame_p.append(self.img_model.sample_prior(frame[0]))\n",
    "        return self.seq_model.sample_prior(torch.stack(frame_p))\n",
    "    \n",
    "    def discriminator(self, x, z_img, z_seq):\n",
    "        reps = []\n",
    "        for frame, z in zip(x.split(1), z_img.split(1)):\n",
    "            z_proj = self.dis_proj(z[0])\n",
    "            z_proj = z_proj.view(z_proj.shape[0], 1, self.img_size, self.img_size)\n",
    "            i = torch.cat((frame[0], z_proj), dim=1)\n",
    "            h = self.dis_blocks(i)\n",
    "            h = h.view(h.shape[0], 256*self.ds_size**2)\n",
    "            rep = self.dis_rep(h)\n",
    "            reps.append(rep)\n",
    "        _, states = self.dis_lstm(torch.stack(reps), z_seq)\n",
    "        h = torch.cat((states[0].view(states[0].shape[1], 2*self.seq_latent_dim), states[1].view(states[1].shape[1], 2*self.seq_latent_dim)), dim=1)\n",
    "        out = self.dis_layer(h)\n",
    "        return out\n",
    "    \n",
    "    def sample_posterior(self, x):\n",
    "        frame_q = []\n",
    "        for frame in s.split(1):\n",
    "            frame_q.append(self.img_model.sample_posterior(frame[0]))\n",
    "        return self.seq_model.sample_posterior(torch.stack(frame_q))\n",
    "    \n",
    "    def decoder(self, z, num_steps):\n",
    "        reps = self.seq_model.decoder(z, num_steps)\n",
    "        frames = []\n",
    "        for rep in reps.split(1):\n",
    "            frame = self.img_model.decoder(rep[0])\n",
    "            frames.append(frame)\n",
    "        return torch.stack(frames)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z_p_img = []\n",
    "        z_q_img = []\n",
    "        img_dis_loss =  []\n",
    "        img_gen_loss = []\n",
    "        for frame in x.split(1):\n",
    "            z_p, z_q, dis_loss, gen_loss = self.img_model.forward(frame[0])\n",
    "            z_p_img.append(z_p)\n",
    "            z_q_img.append(z_q)\n",
    "            img_dis_loss.append(dis_loss)\n",
    "            img_gen_loss.append(gen_loss)\n",
    "        z_p_img = torch.stack(z_p_img)\n",
    "        z_q_img = torch.stack(z_q_img)\n",
    "        img_dis_loss = sum(img_dis_loss)\n",
    "        img_gen_loss = sum(img_gen_loss)\n",
    "        \n",
    "        z_p_seq, z_q_seq, seq_dis_loss, seq_gen_loss = self.seq_model.forward(z_q_img.detach())\n",
    "        \n",
    "        log_d_prior = self.discriminator(x, z_p_img, z_p_seq)\n",
    "        log_d_posterior = self.discriminator(x, z_q_img, z_q_seq)\n",
    "        \n",
    "        dis_loss = torch.mean(\n",
    "            torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                log_d_posterior, torch.ones_like(log_d_posterior))\n",
    "            + torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                log_d_prior, torch.zeros_like(log_d_prior)))\n",
    "        \n",
    "        x_recon = self.decoder(z_q_seq, self.seq_len)\n",
    "        recon_likelihood = -torch.nn.functional.binary_cross_entropy(\n",
    "                                                x_recon, x)*x.data.shape[1]\n",
    "        \n",
    "        gen_loss = torch.mean(log_d_posterior)-torch.mean(recon_likelihood)\n",
    "        \n",
    "        return img_dis_loss, img_gen_loss, seq_dis_loss, seq_gen_loss, dis_loss, gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VideoAVB(256, 3, 64, 20, 64).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dis_params = []\n",
    "img_gen_params = []\n",
    "seq_dis_params = []\n",
    "seq_gen_params = []\n",
    "dis_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if 'img_model.dis' in name:\n",
    "        img_dis_params.append(param)\n",
    "    elif 'seq_model.dis' in name:\n",
    "        seq_dis_params.append(param)\n",
    "    elif 'dis' in name:\n",
    "        dis_params.append(param)\n",
    "    elif 'img_model' in name:\n",
    "        img_gen_params.append(param)\n",
    "    elif 'seq_model' in name:\n",
    "        seq_gen_params.append(param)\n",
    "    else:\n",
    "        assert False  # all params should be covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dis_optimizer = torch.optim.Adam(img_dis_params, lr=1e-3)\n",
    "img_gen_optimizer = torch.optim.Adam(img_gen_params, lr=1e-3)\n",
    "seq_dis_optimizer = torch.optim.Adam(seq_dis_params, lr=1e-3)\n",
    "seq_gen_optimizer = torch.optim.Adam(seq_gen_params, lr=1e-3)\n",
    "dis_optimizer = torch.optim.Adam(dis_params, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "global_step = 0\n",
    "checkpoint_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs = Variable(data.permute(1, 0, 2, 3, 4), requires_grad=False).cuda()  # (t, b, c, h, w)\n",
    "        img_dis_loss, img_gen_loss, seq_dis_loss, seq_gen_loss, dis_loss, gen_loss = model.forward(inputs)\n",
    "        \n",
    "        img_dis_optimizer.zero_grad()\n",
    "        img_dis_loss.backward(retain_graph=True)\n",
    "        img_dis_optimizer.step()\n",
    "        \n",
    "        img_gen_optimizer.zero_grad()\n",
    "        img_gen_loss.backward(retain_graph=True)\n",
    "        img_gen_optimizer.step()\n",
    "        \n",
    "        seq_dis_optimizer.zero_grad()\n",
    "        seq_dis_loss.backward(retain_graph=True)\n",
    "        seq_dis_optimizer.step()\n",
    "        \n",
    "        seq_gen_optimizer.zero_grad()\n",
    "        seq_gen_loss.backward(retain_graph=True)\n",
    "        seq_gen_optimizer.step()\n",
    "        \n",
    "        dis_optimizer.zero_grad()\n",
    "        dis_loss.backward(retain_graph=True)\n",
    "        dis_optimizer.step()\n",
    "        \n",
    "#         experiment.log_metric(\"loss\", loss.item(), step=global_step)\n",
    "        print(\"(Epoch {}) (Global Step {}) (Img Dis Loss {}) (Img Gen Loss {}) (Seq Dis Loss {}) (Seq Gen {}) (Dis Loss {})\".format(\n",
    "            epoch, global_step, img_dis_loss.item(), img_gen_loss.item(), seq_dis_loss.item(), seq_gen_loss.item(), dis_loss.item()), end='\\r', flush=True)\n",
    "#         if i % checkpoint_interval == 0:\n",
    "#             torch.save(model.state_dict(), \"../experiments/obama_avb/checkpoints/model_{}.pth\".format(global_step))\n",
    "#             torch.save(optimizer.state_dict(), \"../experiments/obama_avb/checkpoints/optimizer_{}.pth\".format(global_step))\n",
    "        global_step += 1\n",
    "    print(\"Epoch {} done!\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
